# -*- coding: utf-8 -*-
"""queries anomaly detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l37c7MWlJgyQHzGw5r4SsG4ShSqq6lN6
"""

from google.colab import files

uploaded = files.upload()

import pandas as pd
from collections import Counter
import re
import plotly.express as px
import plotly.io as pio
pio.templates.default = "plotly_white"

queries_df = pd.read_csv("Queries.csv")
print(queries_df.head())

# Cleaning CTR column
queries_df['CTR'] = queries_df['CTR'].str.rstrip('%').astype('float') / 100

# Function to clean and split the queries into words
def clean_and_split(query):
    words = re.findall(r'\b[a-zA-Z]+\b', query.lower())
    return words

# Split each query into words and count the frequency of each word
word_counts = Counter()
for query in queries_df['Top queries']:
    word_counts.update(clean_and_split(query))

word_freq_df = pd.DataFrame(word_counts.most_common(20), columns=['Word', 'Frequency'])

# Plotting the word frequencies
fig = px.bar(word_freq_df, x='Word', y='Frequency', title='Top 20 Most Common Words in Search Queries')
fig.show()

# Top queries by Clicks and Impressions
top_queries_clicks_vis = queries_df.nlargest(10, 'Clicks')[['Top queries', 'Clicks']]
top_queries_impressions_vis = queries_df.nlargest(10, 'Impressions')[['Top queries', 'Impressions']]

# Plotting
fig_clicks = px.bar(top_queries_clicks_vis, x='Top queries', y='Clicks', title='Top Queries by Clicks')
fig_impressions = px.bar(top_queries_impressions_vis, x='Top queries', y='Impressions', title='Top Queries by Impressions')
fig_clicks.show()
fig_impressions.show()

# Remove '%' and convert CTR to float
queries_df['CTR'] = queries_df['CTR'].str.replace('%', '').astype(float)

# Now your features are numeric
features = queries_df[['Clicks', 'Impressions', 'CTR', 'Position']]

from sklearn.ensemble import IsolationForest
import pandas as pd

# Clean CTR column (handle mix of numbers and strings with %)
queries_df['CTR'] = (
    queries_df['CTR']
    .astype(str)
    .str.replace('%', '', regex=False)
    .astype(float)
)

# Ensure Position is numeric too (just in case)
queries_df['Position'] = pd.to_numeric(queries_df['Position'], errors='coerce')

# Selecting relevant features
features = queries_df[['Clicks', 'Impressions', 'CTR', 'Position']]

# Initializing Isolation Forest
iso_forest = IsolationForest(n_estimators=100, contamination=0.01, random_state=42)

# Fitting the model
iso_forest.fit(features)

# Predicting anomalies
queries_df['anomaly'] = iso_forest.predict(features)

# Filtering out anomalies
anomalies = queries_df[queries_df['anomaly'] == -1]

print(anomalies[['Top queries', 'Clicks', 'Impressions', 'CTR', 'Position']])